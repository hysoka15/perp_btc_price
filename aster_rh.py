import requests
import time
import hmac
import random
import hashlib
import logging
import pandas as pd
import csv
import sys
import traceback
import os
import datetime


# Configure logging
def setup_logging():
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = "logs"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    
    # åˆ›å»ºå½“å‰æ—¥æœŸæ—¶é—´çš„å­—ç¬¦ä¸²ï¼Œç”¨äºæ—¥å¿—æ–‡ä»¶å
    current_time = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # è®¾ç½®ä¸»æ—¥å¿—æ–‡ä»¶
    main_log_file = os.path.join(log_dir, f"aster_{current_time}.log")
    
    # è®¾ç½®é”™è¯¯æ—¥å¿—æ–‡ä»¶
    error_log_file = os.path.join(log_dir, f"aster_error_{current_time}.log")
    
    # é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    
    # è®¾ç½®æ—¥å¿—æ ¼å¼
    log_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(log_format)
    root_logger.addHandler(console_handler)
    
    # åˆ›å»ºä¸»æ—¥å¿—æ–‡ä»¶å¤„ç†å™¨
    file_handler = logging.FileHandler(main_log_file, encoding='utf-8')
    file_handler.setFormatter(log_format)
    root_logger.addHandler(file_handler)
    
    # åˆ›å»ºé”™è¯¯æ—¥å¿—æ–‡ä»¶å¤„ç†å™¨ï¼Œåªè®°å½•é”™è¯¯å’Œä¸¥é‡é”™è¯¯
    error_file_handler = logging.FileHandler(error_log_file, encoding='utf-8')
    error_file_handler.setLevel(logging.ERROR)
    error_file_handler.setFormatter(log_format)
    root_logger.addHandler(error_file_handler)
    
    return main_log_file, error_log_file

# è®¾ç½®æ—¥å¿—
main_log_file, error_log_file = setup_logging()
logger = logging.getLogger('AsterDexClient')
logger.info(f"æ—¥å¿—å·²è®¾ç½®ã€‚ä¸»æ—¥å¿—æ–‡ä»¶: {main_log_file}, é”™è¯¯æ—¥å¿—æ–‡ä»¶: {error_log_file}")


# æ·»åŠ ä¸€ä¸ªä¸“é—¨è®°å½•äº¤æ˜“é”™è¯¯çš„å‡½æ•°
def log_trade_error(error_type, account_id, group_id, details, exception=None):
    """è®°å½•äº¤æ˜“é”™è¯¯åˆ°é”™è¯¯æ—¥å¿—
    
    Args:
        error_type: é”™è¯¯ç±»å‹ (å¦‚ "å¼€ä»“å¤±è´¥", "å¹³ä»“å¤±è´¥")
        account_id: è´¦æˆ·ID
        group_id: åˆ†ç»„ID
        details: é”™è¯¯è¯¦æƒ…
        exception: å¼‚å¸¸å¯¹è±¡
    """
    error_msg = f"[äº¤æ˜“é”™è¯¯] {error_type} - è´¦æˆ· {account_id} (åˆ†ç»„ {group_id}): {details}"
    if exception:
        error_msg += f"\nå¼‚å¸¸: {str(exception)}\n{traceback.format_exc()}"
    
    logger.error(error_msg)
    
    # é¢å¤–è®°å½•åˆ°ä¸“é—¨çš„æ–‡ä»¶ (å¯é€‰)
    with open("failed_accounts.log", "a", encoding='utf-8') as f:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        f.write(f"{timestamp} - {error_msg}\n")
        if exception:
            f.write(f"å¼‚å¸¸è¯¦æƒ…: {str(exception)}\n")
            f.write(f"å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}\n")
        f.write("-" * 80 + "\n")


def wait_random(a, b):
    t = random.uniform(a, b)
    logger.info(f"éšæœºç­‰å¾… {t:.2f} ç§’...")
    time.sleep(t)

# æ·»åŠ APIè¯·æ±‚é—´éš”æ—¶é—´
API_REQUEST_DELAY = 1.0  # æ¯æ¬¡APIè¯·æ±‚åç­‰å¾…1ç§’

class AsterRestClient:
    def __init__(self, api_key: str, api_secret: str, base_url: str = "https://fapi.asterdex.com", 
                 proxy_url: str = None, proxy_username: str = None, proxy_password: str = None):
        self.api_key = api_key
        self.api_secret = api_secret.encode()
        self.base_url = base_url
        self.session = requests.Session()
        
        # é…ç½®ä»£ç†
        if proxy_url:
            self._setup_proxy(proxy_url, proxy_username, proxy_password)
        
        self.session.headers.update({"X-MBX-APIKEY": self.api_key})
        self._time_offset = 0
        self.sync_time()
    
    def _setup_proxy(self, proxy_url: str, username: str = None, password: str = None):
        """æ™ºèƒ½ä»£ç†é…ç½® - ä¼˜å…ˆSOCKS5hï¼Œå¤‡ç”¨HTTP"""
        try:
            logger.info(f"ä»£ç†é…ç½®: {proxy_url} (ç”¨æˆ·å: {username})")
            
            success = False
            working_method = None
            
            if username and password:
                # æ–¹æ¡ˆ1: SOCKS5h (æœ€ä½³é€‰æ‹©ï¼Œå®Œå…¨éšè—IP)
                socks5h_proxy = f"socks5h://{username}:{password}@{proxy_url}"
                try:
                    logger.info("å°è¯•SOCKS5hä»£ç†é…ç½®...")
                    proxies = {
                        'http': socks5h_proxy,
                        'https': socks5h_proxy
                    }
                    self.session.proxies.clear()
                    self.session.proxies.update(proxies)
                    
                    # SOCKS5æµ‹è¯•éœ€è¦æ›´é•¿æ—¶é—´
                    if self._test_proxy_with_timeout("SOCKS5h", 15):
                        logger.info("âœ… SOCKS5hä»£ç†é…ç½®æˆåŠŸ (å®Œå…¨éšè—IP)")
                        working_method = "SOCKS5h"
                        success = True
                    else:
                        logger.warning("âŒ SOCKS5hæµ‹è¯•å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ")
                        
                except Exception as e:
                    logger.warning(f"SOCKS5hé…ç½®å¤±è´¥: {str(e)}")
                
                # æ–¹æ¡ˆ2: HTTPä»£ç† (å¤‡ç”¨æ–¹æ¡ˆ)
                if not success:
                    try:
                        logger.info("å°è¯•HTTPä»£ç†é…ç½®...")
                        http_proxy = f"http://{username}:{password}@{proxy_url}"
                        proxies = {
                            'http': http_proxy,
                            'https': http_proxy
                        }
                        self.session.proxies.clear()
                        self.session.proxies.update(proxies)
                        
                        if self._test_proxy("HTTP"):
                            logger.info("âœ… HTTPä»£ç†é…ç½®æˆåŠŸ (å¯èƒ½æš´éœ²HTTPSè¯·æ±‚IP)")
                            working_method = "HTTP"
                            success = True
                        else:
                            logger.warning("âŒ HTTPä»£ç†æµ‹è¯•å¤±è´¥")
                            
                    except Exception as e:
                        logger.warning(f"HTTPä»£ç†é…ç½®å¤±è´¥: {str(e)}")
                
                # æ–¹æ¡ˆ3: ä»…HTTPä»£ç† (æœ€åå¤‡ç”¨)
                if not success:
                    try:
                        logger.info("å°è¯•ä»…HTTPä»£ç†é…ç½®...")
                        http_proxy = f"http://{username}:{password}@{proxy_url}"
                        proxies = {'http': http_proxy}  # ä»…HTTP
                        self.session.proxies.clear()
                        self.session.proxies.update(proxies)
                        
                        if self._test_proxy("HTTPä»…é™"):
                            logger.warning("âš ï¸ ä»…HTTPä»£ç†é…ç½®æˆåŠŸ (HTTPSè¯·æ±‚å°†æš´éœ²çœŸå®IP)")
                            working_method = "HTTPä»…é™"
                            success = True
                            
                    except Exception as e:
                        logger.warning(f"ä»…HTTPä»£ç†é…ç½®å¤±è´¥: {str(e)}")
            
            if not success:
                logger.error("ğŸš« æ‰€æœ‰ä»£ç†æ–¹æ¡ˆå¤±è´¥ï¼Œä½¿ç”¨ç›´è¿")
                self.session.proxies.clear()
                working_method = "ç›´è¿"
            
            # æœ€ç»ˆéªŒè¯
            if working_method:
                self._verify_ip_privacy(working_method)
            
        except Exception as e:
            logger.error(f"ä»£ç†é…ç½®å¤±è´¥: {str(e)}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ç¨‹åºç»§ç»­è¿è¡Œ
    
    def _test_proxy(self, method_name="ä»£ç†"):
        """æµ‹è¯•ä»£ç†è¿æ¥"""
        return self._test_proxy_with_timeout(method_name, 10)
    
    def _test_proxy_with_timeout(self, method_name="ä»£ç†", timeout=10):
        """å¸¦è‡ªå®šä¹‰è¶…æ—¶çš„ä»£ç†æµ‹è¯•"""
        try:
            test_url = "http://httpbin.org/ip"
            response = self.session.get(test_url, timeout=timeout)
            if response.status_code == 200:
                ip_info = response.json()
                detected_ip = ip_info.get('origin', 'unknown')
                logger.info(f"{method_name}æµ‹è¯•æˆåŠŸï¼Œå½“å‰IP: {detected_ip}")
                return True
            else:
                logger.warning(f"{method_name}æµ‹è¯•å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return False
        except Exception as e:
            logger.warning(f"{method_name}æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    def _verify_ip_privacy(self, method_name):
        """éªŒè¯IPéšç§ä¿æŠ¤æ•ˆæœ"""
        try:
            logger.info(f"ğŸ” éªŒè¯{method_name}çš„IPéšç§ä¿æŠ¤...")
            
            # æµ‹è¯•HTTPSè¯·æ±‚
            response = self.session.get("https://httpbin.org/ip", timeout=10)
            if response.status_code == 200:
                ip_info = response.json()
                https_ip = ip_info.get('origin', 'unknown')
                logger.info(f"HTTPSè¯·æ±‚IP: {https_ip}")
                
                # æµ‹è¯•Aster API
                response = self.session.get(f"{self.base_url}/fapi/v1/time", timeout=10)
                if response.status_code == 200:
                    if method_name == "SOCKS5h":
                        logger.info("ğŸ”’ AsteræœåŠ¡å™¨çœ‹åˆ°: ä»£ç†IP (å®Œå…¨éšè—)")
                    elif method_name == "HTTP":
                        logger.warning("âš ï¸ AsteræœåŠ¡å™¨å¯èƒ½çœ‹åˆ°: ä»£ç†IPæˆ–çœŸå®IP")
                    elif method_name == "HTTPä»…é™":
                        logger.warning("ğŸ”“ AsteræœåŠ¡å™¨çœ‹åˆ°: çœŸå®IP (HTTPSç›´è¿)")
                    else:
                        logger.error("ğŸš« AsteræœåŠ¡å™¨çœ‹åˆ°: çœŸå®IP (ç›´è¿)")
                else:
                    logger.error(f"Aster APIæµ‹è¯•å¤±è´¥: {response.status_code}")
            else:
                logger.warning(f"HTTPSæµ‹è¯•å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            logger.warning(f"IPéšç§éªŒè¯å¤±è´¥: {str(e)}")

    def sync_time(self):
        # è·å–æœåŠ¡å™¨æ—¶é—´ï¼Œæ ¡å‡†æœ¬åœ°æ—¶é—´æˆ³
        url = f"{self.base_url}/fapi/v1/time"
        resp = self.session.get(url)
        resp.raise_for_status()
        server_time = resp.json()["serverTime"]
        local_time = int(time.time() * 1000)
        self._time_offset = server_time - local_time

    def _timestamp(self):
        # è¿”å›æ ¡å‡†åçš„æ—¶é—´æˆ³
        return int(time.time() * 1000) + self._time_offset

    def _sign(self, params: dict) -> str:
        # æŒ‰ç…§keyé¡ºåºæ‹¼æ¥å‚æ•°
        query_string = "&".join([f"{k}={params[k]}" for k in sorted(params)])
        signature = hmac.new(self.api_secret, query_string.encode(), hashlib.sha256).hexdigest()
        return signature

    def get_account_balance(self, recvWindow: int = 20000):
        """è·å–è´¦æˆ·ä½™é¢ä¿¡æ¯"""
        max_retries = 4
        for retry in range(max_retries):
            try:
                url_time = f"{self.base_url}/fapi/v1/time"
                resp_time = requests.get(url_time)
                resp_time.raise_for_status()
                timestamp = resp_time.json()["serverTime"]
                
                params = {
                    "recvWindow": recvWindow,
                    "timestamp": timestamp
                }
                query_string = "&".join([f"{k}={params[k]}" for k in sorted(params)])
                signature = hmac.new(self.api_secret, query_string.encode(), hashlib.sha256).hexdigest()
                url = f"{self.base_url}/fapi/v2/balance?{query_string}&signature={signature}"
                headers = {"X-MBX-APIKEY": self.api_key}
                
                resp = requests.get(url, headers=headers)
                resp.raise_for_status()
                return resp.json()
            except Exception as e:
                if retry < max_retries - 1:
                    logger.warning(f"è·å–è´¦æˆ·ä½™é¢å¤±è´¥ï¼Œ3ç§’åé‡è¯• ({retry+1}/{max_retries}): {str(e)}")
                    time.sleep(3)
                else:
                    logger.error(f"è·å–è´¦æˆ·ä½™é¢å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {str(e)}")
                    raise
        
    def get_max_quantity(self, symbol: str, leverage: int = 100):
        """è®¡ç®—æœ€å¤§å¯ä¹°å–æ•°é‡"""
        max_retries = 3
        for retry in range(max_retries):
            try:
                # è·å–è´¦æˆ·ä½™é¢
                balances = self.get_account_balance()
                usdt_balance = 0
                
                # æ‰¾åˆ°USDTä½™é¢
                for asset in balances:
                    if asset.get("asset") == "USDT":
                        usdt_balance = float(asset.get("availableBalance", 0))
                        break
                
                # è·å–å½“å‰BTCä»·æ ¼
                url = f"{self.base_url}/fapi/v1/ticker/price?symbol={symbol}"
                resp = requests.get(url)
                resp.raise_for_status()
                btc_price = float(resp.json().get("price", 0))
                
                if btc_price <= 0:
                    raise ValueError("æ— æ³•è·å–æœ‰æ•ˆçš„BTCä»·æ ¼")
                
                # è®¡ç®—æœ€å¤§å¯ä¹°æ•°é‡(è€ƒè™‘æ æ†)
                max_usdt = usdt_balance * leverage
                max_quantity = max_usdt / btc_price
                
                # æŒ‰BTCçš„æœ€å°äº¤æ˜“å•ä½è¿›è¡Œå››èˆäº”å…¥
                # é€šå¸¸BTCæœ€å°å•ä½æ˜¯0.001
                precision = 3
                max_quantity = round(max_quantity, precision)
                
                logger.info(f"è´¦æˆ·USDTä½™é¢: {usdt_balance}, BTCä»·æ ¼: {btc_price}, æœ€å¤§å¯äº¤æ˜“æ•°é‡: {max_quantity}")
                return max_quantity
            except Exception as e:
                if retry < max_retries - 1:
                    logger.warning(f"è®¡ç®—æœ€å¤§äº¤æ˜“æ•°é‡å¤±è´¥ï¼Œ3ç§’åé‡è¯• ({retry+1}/{max_retries}): {str(e)}")
                    time.sleep(3)
                else:
                    logger.error(f"è®¡ç®—æœ€å¤§äº¤æ˜“æ•°é‡å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {str(e)}")
                    raise

    def set_leverage(self, symbol: str, leverage: int, recvWindow: int = 20000):
        max_retries = 3
        for retry in range(max_retries):
            try:
                # 1. è·å–æœåŠ¡å™¨æ—¶é—´
                url_time = f"{self.base_url}/fapi/v1/time"
                resp_time = requests.get(url_time)
                resp_time.raise_for_status()
                timestamp = resp_time.json()["serverTime"]
                
                # 2. å‚æ•°æŒ‰å­—å…¸åºæ‹¼æ¥
                params = {
                    "symbol": symbol,
                    "leverage": leverage,
                    "recvWindow": recvWindow,
                    "timestamp": timestamp
                }
                query_string = "&".join([f"{k}={params[k]}" for k in sorted(params)])
                
                # 3. ç”¨apiSecretåšHMAC SHA256ç­¾å
                signature = hmac.new(self.api_secret, query_string.encode(), hashlib.sha256).hexdigest()
                
                # 4. æ‹¼æ¥å®Œæ•´URL
                url = f"{self.base_url}/fapi/v1/leverage?{query_string}&signature={signature}"
                headers = {"X-MBX-APIKEY": self.api_key}
                
                resp = requests.post(url, headers=headers)
                resp.raise_for_status()
                result = resp.json()
                logger.info(f"è®¾ç½®æ æ†: {result['symbol']} æ æ†: {result['leverage']}å€")
                return result
            except Exception as e:
                if retry < max_retries - 1:
                    logger.warning(f"è®¾ç½®æ æ†å¤±è´¥ï¼Œ3ç§’åé‡è¯• ({retry+1}/{max_retries}): {str(e)}")
                    time.sleep(3)
                else:
                    logger.error(f"è®¾ç½®æ æ†å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {str(e)}")
                    raise

    def create_order(self, symbol: str, side: str, quantity: float, leverage: int = 100, recvWindow: int = 20000):
        max_retries = 3
        for retry in range(max_retries):
            try:
                # å…ˆè°ƒæ•´æ æ†
                self.set_leverage(symbol, leverage, recvWindow)
                
                # 1. è·å–æœåŠ¡å™¨æ—¶é—´
                url_time = f"{self.base_url}/fapi/v1/time"
                resp_time = requests.get(url_time)
                resp_time.raise_for_status()
                timestamp = resp_time.json()["serverTime"]
                
                # 2. å‚æ•°æŒ‰å­—å…¸åºæ‹¼æ¥
                params = {
                    "symbol": symbol,
                    "side": side,
                    "type": "MARKET",
                    "quantity": quantity,
                    "recvWindow": recvWindow,
                    "timestamp": timestamp
                }
                query_string = "&".join([f"{k}={params[k]}" for k in sorted(params)])
                
                # 3. ç”¨apiSecretåšHMAC SHA256ç­¾å
                signature = hmac.new(self.api_secret, query_string.encode(), hashlib.sha256).hexdigest()
                
                # 4. æ‹¼æ¥å®Œæ•´URL
                url = f"{self.base_url}/fapi/v1/order?{query_string}&signature={signature}"
                headers = {"X-MBX-APIKEY": self.api_key}
                
                resp = requests.post(url, headers=headers)
                resp.raise_for_status()
                result = resp.json()
                logger.info(f"ä¸‹å•æˆåŠŸ: {result['symbol']} {result['side']} {result['origQty']} å•å·: {result['orderId']}")
                return result
            except Exception as e:
                if retry < max_retries - 1:
                    logger.warning(f"ä¸‹å•å¤±è´¥ï¼Œ3ç§’åé‡è¯• ({retry+1}/{max_retries}): {str(e)}")
                    time.sleep(3)
                else:
                    logger.error(f"ä¸‹å•å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {str(e)}")
                    raise

    def cancel_all_orders(self, symbol: str, recvWindow: int = 20000):
        max_retries = 3
        for retry in range(max_retries):
            try:
                # 1. è·å–æœåŠ¡å™¨æ—¶é—´
                url_time = f"{self.base_url}/fapi/v1/time"
                resp_time = requests.get(url_time)
                resp_time.raise_for_status()
                timestamp = resp_time.json()["serverTime"]
                
                # 2. å‚æ•°æŒ‰å­—å…¸åºæ‹¼æ¥
                params = {
                    "symbol": symbol,
                    "recvWindow": recvWindow,
                    "timestamp": timestamp
                }
                query_string = "&".join([f"{k}={params[k]}" for k in sorted(params)])
                
                # 3. ç”¨apiSecretåšHMAC SHA256ç­¾å
                signature = hmac.new(self.api_secret, query_string.encode(), hashlib.sha256).hexdigest()
                
                # 4. æ‹¼æ¥å®Œæ•´URL
                url = f"{self.base_url}/fapi/v1/allOpenOrders?{query_string}&signature={signature}"
                headers = {"X-MBX-APIKEY": self.api_key}
                
                resp = requests.delete(url, headers=headers)
                resp.raise_for_status()
                return resp.json()
            except Exception as e:
                if retry < max_retries - 1:
                    logger.warning(f"å–æ¶ˆæ‰€æœ‰è®¢å•å¤±è´¥ï¼Œ3ç§’åé‡è¯• ({retry+1}/{max_retries}): {str(e)}")
                    time.sleep(3)
                else:
                    logger.error(f"å–æ¶ˆæ‰€æœ‰è®¢å•å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {str(e)}")
                    raise

    def get_positions(self, symbol: str, recvWindow: int = 20000):
        max_retries = 3
        for retry in range(max_retries):
            try:
                # æŸ¥è¯¢å½“å‰æŒä»“
                url_time = f"{self.base_url}/fapi/v1/time"
                resp_time = requests.get(url_time)
                resp_time.raise_for_status()
                timestamp = resp_time.json()["serverTime"]
                params = {
                    "symbol": symbol,
                    "recvWindow": recvWindow,
                    "timestamp": timestamp
                }
                query_string = "&".join([f"{k}={params[k]}" for k in sorted(params)])
                signature = hmac.new(self.api_secret, query_string.encode(), hashlib.sha256).hexdigest()
                url = f"{self.base_url}/fapi/v2/positionRisk?{query_string}&signature={signature}"
                headers = {"X-MBX-APIKEY": self.api_key}
                resp = requests.get(url, headers=headers)
                resp.raise_for_status()
                
                positions = resp.json()
                for pos in positions:
                    amt = float(pos.get("positionAmt", 0))
                    if amt != 0:
                        logger.info(f"å½“å‰æŒä»“: {pos['symbol']} æ•°é‡: {pos['positionAmt']} æ–¹å‘: {'å¤š' if float(pos['positionAmt']) > 0 else 'ç©º'} æœªå®ç°ç›ˆäº: {pos['unRealizedProfit']}")
                        
                return positions
            except Exception as e:
                if retry < max_retries - 1:
                    logger.warning(f"è·å–æŒä»“ä¿¡æ¯å¤±è´¥ï¼Œ3ç§’åé‡è¯• ({retry+1}/{max_retries}): {str(e)}")
                    time.sleep(3)
                else:
                    logger.error(f"è·å–æŒä»“ä¿¡æ¯å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {str(e)}")
                    raise

    def close_all_positions(self, symbol: str, recvWindow: int = 20000):
        # æŸ¥è¯¢æ‰€æœ‰æŒä»“æ–¹å‘ï¼Œé€ä¸€å¹³ä»“
        try:
            positions = self.get_positions(symbol, recvWindow)
            closed_positions = []
            
            for pos in positions:
                amt = float(pos.get("positionAmt", 0))
                if amt == 0:
                    continue
                
                position_side = pos.get("positionSide", "BOTH")
                side = "SELL" if amt > 0 else "BUY"
                qty = abs(amt)
                
                # ä½¿ç”¨é‡è¯•æœºåˆ¶è¿›è¡Œå¹³ä»“
                max_retries = 3
                for retry in range(max_retries):
                    try:
                        # 1. è·å–æœåŠ¡å™¨æ—¶é—´
                        url_time = f"{self.base_url}/fapi/v1/time"
                        resp_time = requests.get(url_time)
                        resp_time.raise_for_status()
                        timestamp = resp_time.json()["serverTime"]
                        
                        # 2. å‚æ•°
                        params = {
                            "symbol": symbol,
                            "side": side,
                            "type": "MARKET",
                            "reduceOnly": "true",
                            "quantity": qty,
                            "recvWindow": recvWindow,
                            "timestamp": timestamp
                        }
                        
                        # positionSide åªåœ¨åŒå‘æŒä»“æ—¶éœ€è¦
                        if position_side != "BOTH":
                            params["positionSide"] = position_side
                            
                        query_string = "&".join([f"{k}={params[k]}" for k in sorted(params)])
                        signature = hmac.new(self.api_secret, query_string.encode(), hashlib.sha256).hexdigest()
                        url = f"{self.base_url}/fapi/v1/order?{query_string}&signature={signature}"
                        headers = {"X-MBX-APIKEY": self.api_key}
                        
                        resp = requests.post(url, headers=headers)
                        resp.raise_for_status()
                        result = resp.json()
                        
                        closed_positions.append({
                            "symbol": pos["symbol"],
                            "side": side,
                            "quantity": qty,
                            "profit": pos["unRealizedProfit"]
                        })
                        
                        logger.info(f"å¹³ä»“æˆåŠŸ: {symbol} {side} {qty} å•å·: {result['orderId']}")
                        break  # å¦‚æœæˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                        
                    except Exception as e:
                        if retry < max_retries - 1:
                            logger.warning(f"å¹³ä»“å¤±è´¥ï¼Œ3ç§’åé‡è¯• ({retry+1}/{max_retries}): {str(e)}")
                            time.sleep(3)
                        else:
                            logger.error(f"å¹³ä»“å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {str(e)}")
                            # ç»§ç»­å°è¯•å¹³ä»“å…¶ä»–ä»“ä½
            
            if not closed_positions:
                logger.info("æ²¡æœ‰éœ€è¦å¹³ä»“çš„æŒä»“")
                
            return closed_positions
            
        except Exception as e:
            logger.error(f"å¹³ä»“è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            # è¿”å›ç©ºåˆ—è¡¨è¡¨ç¤ºå¹³ä»“å¤±è´¥
            return []

    def get_usdt_balance(self):
        """è·å–USDTä½™é¢"""
        balances = self.get_account_balance()
        for asset in balances:
            if asset.get("asset") == "USDT":
                return float(asset.get("availableBalance", 0))
        return 0

def load_accounts_from_excel(excel_file):
    """ä»Excelæ–‡ä»¶åŠ è½½è´¦æˆ·ä¿¡æ¯"""
    try:
        df = pd.read_excel(excel_file)
        logger.info(f"å…±è¯»å–åˆ° {len(df)} ä¸ªè´¦æˆ·")
        
        if len(df) < 1:
            logger.error("æœªæ‰¾åˆ°æœ‰æ•ˆè´¦æˆ·ä¿¡æ¯")
            return None
            
        return df
    except Exception as e:
        logger.error(f"åŠ è½½è´¦æˆ·ä¿¡æ¯å¤±è´¥: {str(e)}")
        return None

def close_all_positions_for_accounts(excel_file, symbol="BTCUSDT"):
    """ä¸ºæ‰€æœ‰è´¦æˆ·å¹³ä»“"""
    accounts = load_accounts_from_excel(excel_file)
    if accounts is None:
        return
    
    logger.info(f"å‡†å¤‡ä¸ºæ‰€æœ‰è´¦æˆ·å¹³ä»“ {symbol}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰groupåˆ—ï¼Œç”¨äºåˆ†ç»„è¾“å‡ºç»“æœ
    has_group_column = 'group' in accounts.columns
    
    # åˆå§‹åŒ–æ±‡æ€»æ•°æ®
    groups = {}
    total_initial = 0
    total_final = 0
    
    for idx, row in accounts.iterrows():
        account_id = row['ç¼–å·']
        api_key = str(row['api_key']).strip()
        api_secret = str(row['api_secret']).strip()
        
        # å¦‚æœæœ‰åˆ†ç»„ä¿¡æ¯ï¼Œè®°å½•åˆ†ç»„
        group_id = str(row['group']).strip() if has_group_column else "default"
        
        # è·å–ä»£ç†é…ç½®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        proxy_url = None
        proxy_username = None
        proxy_password = None
        
        if 'proxy_url' in accounts.columns:
            proxy_url = str(row['proxy_url']).strip() if pd.notna(row['proxy_url']) else None
        if 'proxy_username' in accounts.columns:
            proxy_username = str(row['proxy_username']).strip() if pd.notna(row['proxy_username']) else None
        if 'proxy_password' in accounts.columns:
            proxy_password = str(row['proxy_password']).strip() if pd.notna(row['proxy_password']) else None
        
        # åˆå§‹åŒ–åˆ†ç»„æ•°æ®
        if group_id not in groups:
            groups[group_id] = {
                'initial_total': 0,
                'final_total': 0,
                'accounts': []
            }
        
        groups[group_id]['accounts'].append(account_id)
        
        try:
            # åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆå¸¦ä»£ç†æ”¯æŒï¼‰
            client = AsterRestClient(api_key, api_secret, 
                                   proxy_url=proxy_url, 
                                   proxy_username=proxy_username, 
                                   proxy_password=proxy_password)
            logger.info(f"è´¦æˆ· {account_id} (åˆ†ç»„ {group_id}) å¼€å§‹å¹³ä»“")
            
            # è·å–å¹³ä»“å‰ä½™é¢
            balance_before = client.get_usdt_balance()
            logger.info(f"è´¦æˆ· {account_id} å¹³ä»“å‰USDTä½™é¢: {balance_before}")
            
            # å°†ä½™é¢æ·»åŠ åˆ°åˆ†ç»„å’Œæ€»è®¡
            groups[group_id]['initial_total'] += balance_before
            total_initial += balance_before
            
            # å¹³ä»“
            result = client.close_all_positions(symbol=symbol)
            
            # è·å–å¹³ä»“åä½™é¢
            balance_after = client.get_usdt_balance()
            logger.info(f"è´¦æˆ· {account_id} å¹³ä»“åUSDTä½™é¢: {balance_after}")
            
            # æ›´æ–°åˆ†ç»„å’Œæ€»è®¡
            groups[group_id]['final_total'] += balance_after
            total_final += balance_after
            
            # è®¡ç®—å˜åŒ–
            balance_change = balance_after - balance_before
            change_percent = (balance_change/balance_before*100) if balance_before > 0 else 0
            logger.info(f"è´¦æˆ· {account_id} ä½™é¢å˜åŒ–: {balance_change:.8f} USDT ({change_percent:.4f}% å¦‚æœä¸ºæ­£åˆ™ç›ˆåˆ©ï¼Œä¸ºè´Ÿåˆ™äºæŸ)")
            
        except Exception as e:
            error_msg = f"ç´§æ€¥å¹³ä»“å¤±è´¥: {str(e)}"
            log_trade_error("ç´§æ€¥å¹³ä»“å¤±è´¥", account_id, group_id, error_msg, e)
        
        # åœ¨å¤„ç†ä¸‹ä¸€ä¸ªè´¦æˆ·å‰ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œé¿å…APIè¯·æ±‚è¿‡äºé¢‘ç¹
        time.sleep(API_REQUEST_DELAY * 3)
    
    # è¾“å‡ºåˆ†ç»„ç»“æœ
    logger.info("\n===== å¹³ä»“ç»“æœåˆ†æ =====")
    
    # æ˜¾ç¤ºå„ç»„ç»“æœ
    for group_id, data in groups.items():
        change = data['final_total'] - data['initial_total']
        change_percent = (change/data['initial_total']*100) if data['initial_total'] > 0 else 0
        logger.info(f"åˆ†ç»„ {group_id}: åˆå§‹ä½™é¢ {data['initial_total']:.8f} USDT, æœ€ç»ˆä½™é¢ {data['final_total']:.8f} USDT, å‡€å˜åŒ–: {change:.8f} USDT ({change_percent:.4f}%)")
    
    # æ˜¾ç¤ºæ€»ä½“ç»“æœ
    total_change = total_final - total_initial
    change_percent = (total_change/total_initial*100) if total_initial > 0 else 0
    logger.info(f"\næ‰€æœ‰è´¦æˆ·æ€»è®¡: åˆå§‹ä½™é¢ {total_initial:.8f} USDT, æœ€ç»ˆä½™é¢ {total_final:.8f} USDT")
    logger.info(f"æ€»ç›ˆäº: {total_change:.8f} USDT ({change_percent:.4f}%)")

def run_hedge_trading(excel_file, symbol="BTCUSDT", leverage=100, position_percent=0.5, default_wait_time=610):
    """è¿è¡Œå¯¹å†²äº¤æ˜“"""
    # æ‰¹é‡å¤„ç†é’±åŒ…é…ç½®
    df = load_accounts_from_excel(excel_file)
    if df is None:
        return
    
    # ç¡®ä¿è‡³å°‘æœ‰2ä¸ªè´¦æˆ·
    account_count = len(df)
    if account_count < 2:
        logger.error("éœ€è¦è‡³å°‘2ä¸ªè´¦æˆ·è¿›è¡Œå¯¹å†²æ“ä½œ")
        return
    
    # æ£€æŸ¥Excelæ˜¯å¦åŒ…å«groupå’Œwait_timeåˆ—
    has_group_column = 'group' in df.columns
    has_wait_time_column = 'wait_time' in df.columns
    
    if not has_group_column:
        logger.warning("Excelæ–‡ä»¶ä¸­æœªæ‰¾åˆ°'group'åˆ—ï¼Œå°†ä¸ºæ¯2ä¸ªè´¦æˆ·åˆ›å»ºä¸€ä¸ªé»˜è®¤åˆ†ç»„")
    
    if not has_wait_time_column:
        logger.warning(f"Excelæ–‡ä»¶ä¸­æœªæ‰¾åˆ°'wait_time'åˆ—ï¼Œå°†ä½¿ç”¨é»˜è®¤ç­‰å¾…æ—¶é—´{default_wait_time}ç§’")
    
    # åˆå§‹åŒ–æ‰€æœ‰è´¦æˆ·çš„å®¢æˆ·ç«¯å’Œæ•°æ®
    clients = {}
    account_data = {}
    groups = {}
    
    # å¤„ç†æ‰€æœ‰è´¦æˆ·
    for idx, row in df.iterrows():
        account_id = row['ç¼–å·']
        api_key = str(row['api_key']).strip()
        api_secret = str(row['api_secret']).strip()
        
        # è·å–groupä¿¡æ¯ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æ ¹æ®é¡ºåºåˆ†é…
        if has_group_column:
            group = str(row['group']).strip()
        else:
            group = str((idx // 2) + 1)  # æ¯2ä¸ªè´¦æˆ·ä¸€ç»„
        
        # è·å–wait_timeä¿¡æ¯ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
        if has_wait_time_column:
            wait_time = int(row['wait_time'])
        else:
            wait_time = default_wait_time
        
        # è·å–ä»£ç†é…ç½®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        proxy_url = None
        proxy_username = None
        proxy_password = None
        
        if 'proxy_url' in df.columns:
            proxy_url = str(row['proxy_url']).strip() if pd.notna(row['proxy_url']) else None
        if 'proxy_username' in df.columns:
            proxy_username = str(row['proxy_username']).strip() if pd.notna(row['proxy_username']) else None
        if 'proxy_password' in df.columns:
            proxy_password = str(row['proxy_password']).strip() if pd.notna(row['proxy_password']) else None
        
        try:
            # åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆå¸¦ä»£ç†æ”¯æŒï¼‰
            client = AsterRestClient(api_key, api_secret,
                                   proxy_url=proxy_url,
                                   proxy_username=proxy_username,
                                   proxy_password=proxy_password)
            # è·å–åˆå§‹ä½™é¢
            initial_balance = client.get_usdt_balance()
            # è·å–æœ€å¤§å¯äº¤æ˜“æ•°é‡
            max_qty = client.get_max_quantity(symbol, leverage)
            
            # å­˜å‚¨è´¦æˆ·æ•°æ®
            account_data[account_id] = {
                'client': client,
                'initial_balance': initial_balance,
                'max_quantity': max_qty,
                'group': group,
                'wait_time': wait_time,
                'final_balance': None
            }
            
            # å°†è´¦æˆ·æ·»åŠ åˆ°å¯¹åº”çš„åˆ†ç»„
            if group not in groups:
                groups[group] = []
            groups[group].append(account_id)
            
            logger.info(f"è´¦æˆ· {account_id} åˆå§‹USDTä½™é¢: {initial_balance}, æœ€å¤§å¯äº¤æ˜“æ•°é‡: {max_qty}, åˆ†ç»„: {group}, ç­‰å¾…æ—¶é—´: {wait_time}ç§’")
            
            # æ¯å¤„ç†ä¸€ä¸ªè´¦æˆ·åç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œé¿å…APIè¯·æ±‚è¿‡äºé¢‘ç¹
            time.sleep(API_REQUEST_DELAY * 2)
            
        except Exception as e:
            error_msg = f"è´¦æˆ·åˆå§‹åŒ–å¤±è´¥: {str(e)}"
            log_trade_error("è´¦æˆ·åˆå§‹åŒ–å¤±è´¥", account_id, group, error_msg, e)
    
    # è¿‡æ»¤å‡ºæœ‰æ•ˆçš„åˆ†ç»„ï¼ˆè‡³å°‘åŒ…å«2ä¸ªè´¦æˆ·ï¼‰
    valid_groups = {}
    for group_id, account_ids in groups.items():
        if len(account_ids) >= 2:
            valid_groups[group_id] = account_ids
        else:
            logger.warning(f"åˆ†ç»„ {group_id} åªæœ‰ {len(account_ids)} ä¸ªè´¦æˆ·ï¼Œè‡³å°‘éœ€è¦2ä¸ªè´¦æˆ·æ‰èƒ½è¿›è¡Œå¯¹å†²äº¤æ˜“ï¼Œå°†è·³è¿‡æ­¤åˆ†ç»„")
    
    if not valid_groups:
        logger.error("æ²¡æœ‰æœ‰æ•ˆçš„å¯¹å†²äº¤æ˜“åˆ†ç»„ï¼Œè‡³å°‘éœ€è¦ä¸€ä¸ªåŒ…å«2ä¸ªä»¥ä¸Šè´¦æˆ·çš„åˆ†ç»„")
        return
    
    logger.info(f"å…±æœ‰ {len(valid_groups)} ä¸ªæœ‰æ•ˆäº¤æ˜“åˆ†ç»„")
    
    # åˆ›å»ºä¸€ä¸ªçº¿ç¨‹åˆ—è¡¨ï¼Œç”¨äºè·Ÿè¸ªæ‰€æœ‰å¹³ä»“çº¿ç¨‹
    closing_threads = []
    
    # å¤„ç†æ¯ä¸ªåˆ†ç»„ - é”™å¼€å¼€ä»“æ—¶é—´
    group_processed_count = 0
    for group_id, account_ids in valid_groups.items():
        # å¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªåˆ†ç»„ï¼Œéšæœºç­‰å¾…1-2åˆ†é’Ÿï¼Œé”™å¼€å¼€ä»“æ—¶é—´
        if group_processed_count > 0:
            stagger_wait_time = random.uniform(30, 60)  # 1-2åˆ†é’Ÿçš„éšæœºç­‰å¾…
            logger.info(f"é”™å¼€å¼€ä»“æ—¶é—´: ç­‰å¾… {stagger_wait_time:.1f} ç§’åå¼€å§‹å¤„ç†åˆ†ç»„ {group_id}...")
            time.sleep(stagger_wait_time)
        
        group_processed_count += 1
        group_accounts = [account_data[acc_id] for acc_id in account_ids]
        wait_time = group_accounts[0]['wait_time']  # ä½¿ç”¨ç»„å†…ç¬¬ä¸€ä¸ªè´¦æˆ·çš„ç­‰å¾…æ—¶é—´
        
        logger.info(f"\n===== å¤„ç†åˆ†ç»„ {group_id} =====")
        logger.info(f"åˆ†ç»„ {group_id} åŒ…å« {len(account_ids)} ä¸ªè´¦æˆ·ï¼Œç­‰å¾…æ—¶é—´: {wait_time}ç§’")
        
        # è·å–ç»„å†…æ‰€æœ‰è´¦æˆ·çš„æœ€å°å¯äº¤æ˜“æ•°é‡
        min_quantity = min(account['max_quantity'] for account in group_accounts)
        trade_quantity = min_quantity * position_percent
        trade_quantity = round(trade_quantity, 3)
        logger.info(f"åˆ†ç»„ {group_id} å¯¹å†²äº¤æ˜“æ•°é‡: {trade_quantity} (æœ€å¤§å€¼çš„{position_percent*100}%)")
        
        # åˆ†é…äº¤æ˜“æ–¹å‘ï¼šç¬¬ä¸€ä¸ªè´¦æˆ·åšå¤šï¼Œå…¶ä½™è´¦æˆ·åšç©º
        long_account = account_ids[0]
        short_accounts = account_ids[1:]
        
        # è®¡ç®—æ¯ä¸ªåšç©ºè´¦æˆ·çš„äº¤æ˜“é‡ï¼Œç¡®ä¿ç²¾ç¡®åŒ¹é…
        if len(short_accounts) > 0:
            # ä¿æŒåŸæœ‰ç²¾åº¦
            total_short_quantity = trade_quantity
            
            # è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„åŸºç¡€æ•°é‡ï¼ˆä¸å¤„ç†ä½™æ•°ï¼‰
            base_short_quantity = total_short_quantity / len(short_accounts)
            base_short_quantity_rounded = round(base_short_quantity, 3)
            
            # è®¡ç®—ä½¿ç”¨åŸºç¡€æ•°é‡åçš„æ€»é‡
            base_total = base_short_quantity_rounded * len(short_accounts)
            
            # è®¡ç®—ä½™é‡ï¼ˆå¯èƒ½æœ‰æ­£è´Ÿï¼‰
            remainder = round(total_short_quantity - base_total, 3)
            
            # åˆ†é…å„è´¦æˆ·çš„åšç©ºé‡
            short_quantities = [base_short_quantity_rounded] * len(short_accounts)
            
            # å¦‚æœæœ‰ä½™é‡ï¼Œåˆ†é…ç»™ç¬¬ä¸€ä¸ªåšç©ºè´¦æˆ·
            if remainder != 0:
                short_quantities[0] = round(short_quantities[0] + remainder, 3)
            
            # éªŒè¯æ€»å’Œæ˜¯å¦æ­£ç¡®
            actual_short_total = sum(short_quantities)
            logger.info(f"åˆ†ç»„ {group_id} åšå¤šæ•°é‡: {trade_quantity}, åšç©ºæ€»æ•°é‡: {actual_short_total} (è´¦æˆ·åˆ†é…: {short_quantities})")
            
            if round(actual_short_total, 3) != round(trade_quantity, 3):
                logger.warning(f"åˆ†ç»„ {group_id} åšç©ºæ€»é‡ {actual_short_total} ä¸åšå¤šé‡ {trade_quantity} ä¸ä¸€è‡´ï¼Œå·®é¢: {round(trade_quantity - actual_short_total, 6)}")
        else:
            logger.error(f"åˆ†ç»„ {group_id} æ²¡æœ‰åšç©ºè´¦æˆ·ï¼Œæ— æ³•è¿›è¡Œå¯¹å†²äº¤æ˜“")
            continue
        
        # åšå¤šè´¦æˆ·å¼€ä»“
        try:
            logger.info(f"åˆ†ç»„ {group_id} - è´¦æˆ· {long_account} å¼€å§‹åšå¤š {symbol}, æ•°é‡: {trade_quantity}")
            account_data[long_account]['client'].create_order(
                symbol=symbol, 
                side="BUY", 
                quantity=trade_quantity, 
                leverage=leverage
            )
        except Exception as e:
            error_msg = f"åšå¤šå¤±è´¥: {str(e)}"
            log_trade_error("å¼€ä»“å¤±è´¥(å¤š)", long_account, group_id, error_msg, e)
            continue  # å¦‚æœåšå¤šå¤±è´¥ï¼Œè·³è¿‡è¿™ä¸ªç»„
        
        time.sleep(API_REQUEST_DELAY * 2)
        
        # åšç©ºè´¦æˆ·å¼€ä»“
        short_success = True
        for i, short_account in enumerate(short_accounts):
            try:
                short_qty = short_quantities[i]
                logger.info(f"åˆ†ç»„ {group_id} - è´¦æˆ· {short_account} å¼€å§‹åšç©º {symbol}, æ•°é‡: {short_qty}")
                account_data[short_account]['client'].create_order(
                    symbol=symbol, 
                    side="SELL", 
                    quantity=short_qty, 
                    leverage=leverage
                )
                time.sleep(API_REQUEST_DELAY * 2)
            except Exception as e:
                error_msg = f"åšç©ºå¤±è´¥: æ•°é‡ {short_qty}: {str(e)}"
                log_trade_error("å¼€ä»“å¤±è´¥(ç©º)", short_account, group_id, error_msg, e)
                short_success = False
        
        if not short_success:
            logger.warning(f"åˆ†ç»„ {group_id} æœ‰è´¦æˆ·åšç©ºå¤±è´¥ï¼Œè¯¥ç»„å¯¹å†²å¯èƒ½ä¸å®Œå…¨")
        
        # å¼€å¯ä¸€ä¸ªæ–°çº¿ç¨‹æ¥å¤„ç†è¿™ä¸ªç»„çš„å¹³ä»“
        import threading
        
        def close_group_positions(group_id, account_ids, wait_time):
            logger.info(f"åˆ†ç»„ {group_id} å°†åœ¨ {wait_time} ç§’åå¹³ä»“...")
            time.sleep(wait_time)
            
            logger.info(f"å¼€å§‹å¹³ä»“åˆ†ç»„ {group_id}...")
            for account_id in account_ids:
                try:
                    logger.info(f"åˆ†ç»„ {group_id} - è´¦æˆ· {account_id} å¼€å§‹å¹³ä»“")
                    account_data[account_id]['client'].close_all_positions(symbol=symbol)
                    
                    # è·å–å¹³ä»“åä½™é¢
                    final_balance = account_data[account_id]['client'].get_usdt_balance()
                    account_data[account_id]['final_balance'] = final_balance
                    
                    logger.info(f"åˆ†ç»„ {group_id} - è´¦æˆ· {account_id} å¹³ä»“å®Œæˆ")
                    time.sleep(API_REQUEST_DELAY * 2)
                except Exception as e:
                    error_msg = f"å¹³ä»“å¤±è´¥: {str(e)}"
                    log_trade_error("å¹³ä»“å¤±è´¥", account_id, group_id, error_msg, e)
            
            # è¯¥åˆ†ç»„çš„äº¤æ˜“ç»“æœåˆ†æ
            analyze_group_results(group_id, account_ids, account_data)
        
        # å¯åŠ¨å¹³ä»“çº¿ç¨‹
        closing_thread = threading.Thread(
            target=close_group_positions, 
            args=(group_id, account_ids, wait_time), 
            daemon=True
        )
        closing_thread.start()
        closing_threads.append(closing_thread)
        
        logger.info(f"åˆ†ç»„ {group_id} å¼€ä»“å®Œæˆï¼Œå¹³ä»“çº¿ç¨‹å·²å¯åŠ¨")
    
    # ç­‰å¾…æ‰€æœ‰äº¤æ˜“ç»„å®Œæˆ
    # è®¡ç®—æœ€å¤§ç­‰å¾…æ—¶é—´ï¼šæœ€é•¿æŒä»“æ—¶é—´ + æ¯ç»„é”™å¼€æ—¶é—´ï¼ˆæœ€å¤§å€¼ï¼‰Ã— ç»„æ•° + é¢å¤–ä½™é‡
    max_group_wait_time = max(account_data[acc_id]['wait_time'] for acc_id in account_data)
    max_stagger_time = 180  # æœ€å¤§é”™å¼€æ—¶é—´
    group_count = len(valid_groups)
    extra_buffer_time = 120  # é¢å¤–ç¼“å†²æ—¶é—´
    
    # æ€»æœ€å¤§ç­‰å¾…æ—¶é—´ = æœ€é•¿æŒä»“æ—¶é—´ + æ‰€æœ‰ç»„é”™å¼€æ—¶é—´ + ç¼“å†²
    max_wait_time = max_group_wait_time + (max_stagger_time * (group_count - 1)) + extra_buffer_time
    
    logger.info(f"ç­‰å¾…æ‰€æœ‰äº¤æ˜“ç»„å®Œæˆï¼Œè®¡ç®—è¯¦æƒ…:")
    logger.info(f"- æœ€é•¿æŒä»“æ—¶é—´: {max_group_wait_time}ç§’")
    logger.info(f"- ç»„æ•°: {group_count}ï¼Œæœ€å¤§é”™å¼€æ—¶é—´: {max_stagger_time}ç§’")
    logger.info(f"- é¢å¤–ç¼“å†²æ—¶é—´: {extra_buffer_time}ç§’")
    logger.info(f"- æ€»è®¡æœ€é•¿ç­‰å¾…æ—¶é—´: {max_wait_time}ç§’")
    
    time.sleep(max_wait_time)
    
    # åˆ†ææ€»ä½“äº¤æ˜“ç»“æœ
    analyze_total_results(account_data)
    
    logger.info("æ‰€æœ‰å¯¹å†²äº¤æ˜“å®Œæˆ")

def analyze_group_results(group_id, account_ids, account_data):
    """åˆ†æç‰¹å®šç»„çš„äº¤æ˜“ç»“æœ"""
    logger.info(f"\n===== åˆ†ç»„ {group_id} äº¤æ˜“ç»“æœåˆ†æ =====")
    
    # è®¡ç®—ç»„å†…æ€»åˆå§‹ä½™é¢
    initial_balances = [account_data[acc_id]['initial_balance'] for acc_id in account_ids]
    group_initial_total = sum(initial_balances)
    
    # æ˜¾ç¤ºäº¤æ˜“å‰è´¦æˆ·ä½™é¢
    logger.info(f"åˆ†ç»„ {group_id} äº¤æ˜“å‰ä½™é¢:")
    for acc_id in account_ids:
        initial = account_data[acc_id]['initial_balance']
        logger.info(f"è´¦æˆ· {acc_id}: {initial:.8f} USDT")
    logger.info(f"åˆ†ç»„ {group_id} äº¤æ˜“å‰æ€»ä½™é¢: {group_initial_total:.8f} USDT")
    
    # æ˜¾ç¤ºäº¤æ˜“åè´¦æˆ·ä½™é¢
    logger.info(f"\nåˆ†ç»„ {group_id} äº¤æ˜“åä½™é¢:")
    valid_final_balances = []
    for acc_id in account_ids:
        final = account_data[acc_id]['final_balance']
        if final is not None:
            logger.info(f"è´¦æˆ· {acc_id}: {final:.8f} USDT")
            valid_final_balances.append(final)
        else:
            logger.info(f"è´¦æˆ· {acc_id}: æ— æ³•è·å–ä½™é¢")
    
    # è®¡ç®—ç»„å†…æ€»ç›ˆäº
    if valid_final_balances:
        group_final_total = sum(valid_final_balances)
        group_total_change = group_final_total - group_initial_total
        logger.info(f"åˆ†ç»„ {group_id} äº¤æ˜“åæ€»ä½™é¢: {group_final_total:.8f} USDT")
        logger.info(f"åˆ†ç»„ {group_id} æ€»ç›ˆäº: {group_total_change:.8f} USDT ({group_total_change/group_initial_total*100:.4f}%)")
    else:
        logger.warning(f"åˆ†ç»„ {group_id} æ— æ³•è·å–ä»»ä½•è´¦æˆ·çš„æœ€ç»ˆä½™é¢ï¼Œæ— æ³•è®¡ç®—ç›ˆäº")

def analyze_total_results(account_data):
    """åˆ†ææ‰€æœ‰è´¦æˆ·çš„æ€»ä½“äº¤æ˜“ç»“æœ"""
    logger.info("\n===== æ€»ä½“äº¤æ˜“ç»“æœåˆ†æ =====")
    
    # æŒ‰åˆ†ç»„æ˜¾ç¤ºç»“æœ
    groups = {}
    for acc_id, data in account_data.items():
        group = data['group']
        if group not in groups:
            groups[group] = {
                'accounts': [],
                'initial_total': 0,
                'final_total': 0,
                'has_valid_final': False
            }
        groups[group]['accounts'].append(acc_id)
        groups[group]['initial_total'] += data['initial_balance']
        if data['final_balance'] is not None:
            groups[group]['final_total'] += data['final_balance']
            groups[group]['has_valid_final'] = True
    
    # æ˜¾ç¤ºå„ç»„ç»“æœ
    total_initial = 0
    total_final = 0
    for group_id, data in groups.items():
        total_initial += data['initial_total']
        if data['has_valid_final']:
            total_final += data['final_total']
            change = data['final_total'] - data['initial_total']
            logger.info(f"åˆ†ç»„ {group_id}: åˆå§‹ä½™é¢ {data['initial_total']:.8f} USDT, æœ€ç»ˆä½™é¢ {data['final_total']:.8f} USDT, å‡€å˜åŒ–: {change:.8f} USDT ({change/data['initial_total']*100:.4f}%)")
        else:
            logger.info(f"åˆ†ç»„ {group_id}: åˆå§‹ä½™é¢ {data['initial_total']:.8f} USDT, æ— æ³•è·å–æœ€ç»ˆä½™é¢")
    
    # æ˜¾ç¤ºæ€»ä½“ç»“æœ
    if total_final > 0:
        total_change = total_final - total_initial
        logger.info(f"\næ‰€æœ‰è´¦æˆ·æ€»è®¡: åˆå§‹ä½™é¢ {total_initial:.8f} USDT, æœ€ç»ˆä½™é¢ {total_final:.8f} USDT")
        logger.info(f"æ€»ç›ˆäº: {total_change:.8f} USDT ({total_change/total_initial*100:.4f}%)")

if __name__ == "__main__":
    try:
        # Excelæ–‡ä»¶å
        excel_file = 'accounts_rh.xlsx'  # æ”¹ä¸ºä½ çš„Excelæ–‡ä»¶å
        
        # è®°å½•ç¨‹åºå¼€å§‹
        logger.info("=" * 80)
        logger.info(f"Aster DEX å¯¹å†²äº¤æ˜“ç¨‹åºå¯åŠ¨ - ç‰ˆæœ¬ 1.0")
        logger.info(f"Excelæ–‡ä»¶: {excel_file}")
        logger.info("=" * 80)
        
        # æ£€æŸ¥å‚æ•°ï¼Œç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ç¨‹åºåç§°
        if len(sys.argv) > 1:
            command = sys.argv[1].lower()
            
            # å¦‚æœå‘½ä»¤æ˜¯ closeallï¼Œç›´æ¥å…¨éƒ¨å¹³ä»“
            if command == "closeall":
                logger.info("æ‰§è¡Œç›´æ¥å¹³ä»“å‘½ä»¤")
                try:
                    symbol = "BTCUSDT"
                    # å¦‚æœæä¾›äº†äº¤æ˜“å¯¹å‚æ•°
                    if len(sys.argv) > 2:
                        symbol = sys.argv[2].upper()
                    
                    logger.info(f"å¼€å§‹æ‰§è¡Œæ‰€æœ‰è´¦æˆ·å¹³ä»“æ“ä½œï¼Œäº¤æ˜“å¯¹: {symbol}")
                    close_all_positions_for_accounts(excel_file, symbol)
                    logger.info(f"æ‰€æœ‰è´¦æˆ· {symbol} å¹³ä»“æŒ‡ä»¤å·²æ‰§è¡Œå®Œæ¯•")
                except Exception as e:
                    error_msg = f"å…¨å±€å¹³ä»“è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
                    logger.error(f"{error_msg}\n{traceback.format_exc()}")
                    # è®°å½•åˆ°å¤±è´¥è´¦æˆ·æ—¥å¿—
                    with open("failed_accounts.log", "a", encoding='utf-8') as f:
                        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        f.write(f"{timestamp} - [å…¨å±€é”™è¯¯] {error_msg}\n")
                        f.write(f"å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}\n")
                        f.write("-" * 80 + "\n")
                sys.exit(0)
        
        # é»˜è®¤æ‰§è¡Œå¯¹å†²äº¤æ˜“
        logger.info("å¼€å§‹æ‰§è¡Œå¯¹å†²äº¤æ˜“ç­–ç•¥")
        run_hedge_trading(excel_file)
        logger.info("å¯¹å†²äº¤æ˜“ç¨‹åºæ‰§è¡Œå®Œæ¯•")
        
    except Exception as e:
        error_msg = f"å¯¹å†²äº¤æ˜“ç¨‹åºå‘ç”Ÿå…¨å±€é”™è¯¯: {str(e)}"
        logger.error(f"{error_msg}\n{traceback.format_exc()}")
        # è®°å½•åˆ°å¤±è´¥è´¦æˆ·æ—¥å¿—
        with open("failed_accounts.log", "a", encoding='utf-8') as f:
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            f.write(f"{timestamp} - [å…¨å±€é”™è¯¯] {error_msg}\n")
            f.write(f"å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}\n")
            f.write("-" * 80 + "\n")
    finally:
        # ç¨‹åºç»“æŸè®°å½•
        logger.info("=" * 80)
        logger.info(f"Aster DEX å¯¹å†²äº¤æ˜“ç¨‹åºç»“æŸ - {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("=" * 80)
